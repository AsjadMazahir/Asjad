{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "* import Libraries\n",
    "* Load the data\n",
    "* find the columns with missing values and store in an object\n",
    "* find the columns based on data type\n",
    "    - numeric\n",
    "    - Categoricals\n",
    "    - Boolean\n",
    "* Define the function to impute missing values\n",
    "* apply the function to our dataset with missing values\n",
    "* check the missing values after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at the number of missing columns which are categorical\n",
    "df.isnull().sum()[(df.isnull().sum() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n"
     ]
    }
   ],
   "source": [
    "# find object columns with missing values\n",
    "missing_cat_col = df.select_dtypes(include=['object']).columns[df.select_dtypes(include=['object']).isnull().any()].to_list()\n",
    "print(missing_cat_col)\n",
    "cat_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_data(df, categorical_features):\n",
    "    \"\"\"\n",
    "    Encode categorical data using LabelEncoder for a dataframe having multiple features.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas DataFrame): Input dataframe\n",
    "    categorical_features (list): List of categorical feature names\n",
    "\n",
    "    Returns:\n",
    "    encoded_df (pandas DataFrame): Encoded dataframe\n",
    "    le_dict (dict): Dictionary of LabelEncoders for each categorical feature\n",
    "    \"\"\"\n",
    "    le_dict = {}\n",
    "    encoded_df = df.copy()\n",
    "    for feature in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        encoded_df[feature] = le.fit_transform(encoded_df[feature])\n",
    "        le_dict[feature] = le\n",
    "    return encoded_df, le_dict\n",
    "\n",
    "def inverse_transform_categorical_data(encoded_df, le_dict, categorical_features):\n",
    "    \"\"\"\n",
    "    Inverse transform the encoded categorical data using the stored LabelEncoders.\n",
    "\n",
    "    Parameters:\n",
    "    encoded_df (pandas DataFrame): Encoded dataframe\n",
    "    le_dict (dict): Dictionary of LabelEncoders for each categorical feature\n",
    "    categorical_features (list): List of categorical feature names\n",
    "\n",
    "    Returns:\n",
    "    original_df (pandas DataFrame): Original dataframe with categorical data\n",
    "    \"\"\"\n",
    "    original_df = encoded_df.copy()\n",
    "    for feature in categorical_features:\n",
    "        le = le_dict[feature]\n",
    "        original_df[feature] = le.inverse_transform(original_df[feature])\n",
    "    return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  age  sex  dataset  cp  trestbps   chol  fbs  restecg  thalch  exang  \\\n",
      "0   1   63    1        0   3     145.0  233.0    1        0   150.0      0   \n",
      "1   2   67    1        0   0     160.0  286.0    0        0   108.0      1   \n",
      "2   3   67    1        0   0     120.0  229.0    0        0   129.0      1   \n",
      "3   4   37    1        0   2     130.0  250.0    0        1   187.0      0   \n",
      "4   5   41    0        0   1     130.0  204.0    0        0   172.0      0   \n",
      "\n",
      "   oldpeak  slope   ca  thal  num  \n",
      "0      2.3      0  0.0     0    0  \n",
      "1      1.5      1  3.0     1    2  \n",
      "2      2.6      1  2.0     2    1  \n",
      "3      3.5      0  0.0     1    0  \n",
      "4      1.4      2  0.0     1    0  \n",
      "{'sex': LabelEncoder(), 'dataset': LabelEncoder(), 'cp': LabelEncoder(), 'fbs': LabelEncoder(), 'restecg': LabelEncoder(), 'exang': LabelEncoder(), 'slope': LabelEncoder(), 'thal': LabelEncoder()}\n"
     ]
    }
   ],
   "source": [
    "# data encoding\n",
    "df_encoded, le_dict = encode_categorical_data(df, categorical_features=cat_columns)\n",
    "print(df_encoded.head())\n",
    "print(le_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse transformation\n",
    "#df_original = inverse_transform_categorical_data(df_encoded, le_dict, categorical_features=cat_columns)\n",
    "#print(df_original.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will write a function to impute categorical missing values with random forest classifier\n",
    "\n",
    "def impute_categorical_missing_values_rf(df, categorical_cols, n_estimators= 100, random_state=20):\n",
    "    \"\"\"\n",
    "    This function imputes categorical missing values using Random Forest Classifier.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing missing categorical values.\n",
    "    categorical_cols (list): A list of categorical columns in the DataFrame.\n",
    "    n_estimators (int): The number of estimators in the Random Forest Classifier. Default is 100\n",
    "    random_state (int): The random state for the Random Forest Classifier. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "    imputed_df (DataFrame): The DataFrame with imputed categorical missing values.\n",
    "\n",
    "    Libraries:\n",
    "    The following libraries must be imported for executing the function\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    Data Frame provided as input must be encoded\n",
    "    \"\"\"\n",
    "    # Create a copy of dataframe inorder to avoid modifying it\n",
    "    imputed_df = df.copy()\n",
    "    \n",
    "    # iterate over each categorical column\n",
    "    for col in categorical_cols:\n",
    "        # create a mask to identify missing values\n",
    "        missing_mask = imputed_df[col].isnull()\n",
    "\n",
    "        # check if there are any missing values in the columns\n",
    "        if missing_mask.any():\n",
    "            # create a random forest classifier to impute missing values\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "\n",
    "            # fit the random forest to non missing values\n",
    "            rf.fit(imputed_df[~missing_mask].drop(col, axis=1), imputed_df[~missing_mask][col])\n",
    "\n",
    "            # predict the missing values\n",
    "            predicted_values = rf.predict(imputed_df[missing_mask].drop(col, axis=1))\n",
    "\n",
    "            # replace missing values with predicted values\n",
    "            imputed_df.loc[missing_mask, col] = predicted_values\n",
    "\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  age  sex  dataset  cp  trestbps   chol  fbs  restecg  thalch  exang  \\\n",
      "0      1   63    1        0   3     145.0  233.0    1        0   150.0      0   \n",
      "1      2   67    1        0   0     160.0  286.0    0        0   108.0      1   \n",
      "2      3   67    1        0   0     120.0  229.0    0        0   129.0      1   \n",
      "3      4   37    1        0   2     130.0  250.0    0        1   187.0      0   \n",
      "4      5   41    0        0   1     130.0  204.0    0        0   172.0      0   \n",
      "..   ...  ...  ...      ...  ..       ...    ...  ...      ...     ...    ...   \n",
      "915  916   54    0        3   0     127.0  333.0    1        2   154.0      0   \n",
      "916  917   62    1        3   3       NaN  139.0    0        2     NaN      2   \n",
      "917  918   55    1        3   0     122.0  223.0    1        2   100.0      0   \n",
      "918  919   58    1        3   0       NaN  385.0    1        0     NaN      2   \n",
      "919  920   62    1        3   1     120.0  254.0    0        0    93.0      1   \n",
      "\n",
      "     oldpeak  slope   ca  thal  num  \n",
      "0        2.3      0  0.0     0    0  \n",
      "1        1.5      1  3.0     1    2  \n",
      "2        2.6      1  2.0     2    1  \n",
      "3        3.5      0  0.0     1    0  \n",
      "4        1.4      2  0.0     1    0  \n",
      "..       ...    ...  ...   ...  ...  \n",
      "915      0.0      3  NaN     3    1  \n",
      "916      NaN      3  NaN     3    0  \n",
      "917      0.0      3  NaN     0    2  \n",
      "918      NaN      3  NaN     3    0  \n",
      "919      0.0      3  NaN     3    1  \n",
      "\n",
      "[920 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "imputed_data = impute_categorical_missing_values_rf(df_encoded, cat_columns)\n",
    "print(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    int32  \n",
      " 3   dataset   920 non-null    int32  \n",
      " 4   cp        920 non-null    int32  \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       920 non-null    int32  \n",
      " 8   restecg   920 non-null    int32  \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     920 non-null    int32  \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     920 non-null    int32  \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      920 non-null    int32  \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int32(8), int64(3)\n",
      "memory usage: 86.4 KB\n"
     ]
    }
   ],
   "source": [
    "imputed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
